{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards']\n",
    "stopwords += ['again', 'against', 'all', 'almost', 'alone', 'along']\n",
    "stopwords += ['already', 'also', 'although', 'always', 'am', 'among']\n",
    "stopwords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\n",
    "stopwords += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\n",
    "stopwords += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\n",
    "stopwords += ['because', 'become', 'becomes', 'becoming', 'been']\n",
    "stopwords += ['before', 'beforehand', 'behind', 'being', 'below']\n",
    "stopwords += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\n",
    "stopwords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\n",
    "stopwords += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\n",
    "stopwords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\n",
    "stopwords += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\n",
    "stopwords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\n",
    "stopwords += ['every', 'everyone', 'everything', 'everywhere', 'except']\n",
    "stopwords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\n",
    "stopwords += ['five', 'for', 'former', 'formerly', 'forty', 'found']\n",
    "stopwords += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\n",
    "stopwords += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\n",
    "stopwords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\n",
    "stopwords += ['herself', 'him', 'himself', 'his', 'how', 'however']\n",
    "stopwords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\n",
    "stopwords += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\n",
    "stopwords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\n",
    "stopwords += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\n",
    "stopwords += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\n",
    "stopwords += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\n",
    "stopwords += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none']\n",
    "stopwords += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\n",
    "stopwords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\n",
    "stopwords += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\n",
    "stopwords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\n",
    "stopwords += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\n",
    "stopwords += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\n",
    "stopwords += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\n",
    "stopwords += ['some', 'somehow', 'someone', 'something', 'sometime']\n",
    "stopwords += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\n",
    "stopwords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\n",
    "stopwords += ['then', 'thence', 'there', 'thereafter', 'thereby']\n",
    "stopwords += ['therefore', 'therein', 'thereupon', 'these', 'they']\n",
    "stopwords += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\n",
    "stopwords += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\n",
    "stopwords += ['together', 'too', 'top', 'toward', 'towards', 'twelve']\n",
    "stopwords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\n",
    "stopwords += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\n",
    "stopwords += ['whatever', 'when', 'whence', 'whenever', 'where']\n",
    "stopwords += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\n",
    "stopwords += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\n",
    "stopwords += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\n",
    "stopwords += ['within', 'without', 'would', 'yet', 'you', 'your']\n",
    "stopwords += ['yours', 'yourself', 'yourselves']\n",
    "stopwords += ['--', 'title', 'paid', 'notice', 'corrections']\n",
    "stopwords += ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "stopwords += ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "stopwords += ['united', 'states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def get_freq_dict(year, month, get_meta=False, get_lead=False):\n",
    "    payload = {'api-key': '6ac4e85b86f14ed19183b0f9bdfd73c5'}\n",
    "    in_str = 'https://api.nytimes.com/svc/archive/v1/' + str(year) + '/' + str(month) + '.json'\n",
    "\n",
    "    response = requests.get(in_str, params=payload)\n",
    "    output = response.json()\n",
    "    body = output['response']['docs']\n",
    "    headlines = []\n",
    "    keywords = []\n",
    "    lead_paragraphs = []\n",
    "    \n",
    "    for i in body:\n",
    "        headlines.append(i['headline']['main'])\n",
    "        if get_meta == True:\n",
    "            keywords.append(i['keywords'])\n",
    "        if get_lead == True:\n",
    "            lead_paragraphs.append(i['lead_paragraph'])\n",
    "    \n",
    "    freq_dict = {}\n",
    "    for h in lead_paragraphs:\n",
    "        if h == None:\n",
    "            h = ''\n",
    "        no_punct = re.sub(r'[^\\w\\s]','', h)\n",
    "        curr_head = no_punct.split()\n",
    "        lower_head = [j.lower() for j in curr_head]\n",
    "        # stemmed_head = [ps.stem(j) for j in lower_head]\n",
    "        unique_head = set(lower_head)\n",
    "        final_head = [j for j in unique_head if j not in stopwords]\n",
    "        for i in final_head:\n",
    "            if i in freq_dict:\n",
    "                freq_dict[i] += 1\n",
    "            else:\n",
    "                freq_dict[i] = 1\n",
    "    return freq_dict, headlines, keywords, lead_paragraphs\n",
    "\n",
    "def get_tf_mth(doc_list):\n",
    "    freq_dict = {}\n",
    "    for h in doc_list:\n",
    "        if h == None:\n",
    "            h = ''\n",
    "        no_punct = re.sub(r'[^\\w\\s]','', h)\n",
    "        curr_head = no_punct.split()\n",
    "        lower_head = [j.lower() for j in curr_head]\n",
    "        # stemmed_head = [ps.stem(j) for j in lower_head]\n",
    "        unique_head = set(lower_head)\n",
    "        final_head = [j for j in unique_head if j not in stopwords]\n",
    "        for i in final_head:\n",
    "            if i in freq_dict:\n",
    "                freq_dict[i] += 1\n",
    "            else:\n",
    "                freq_dict[i] = 1\n",
    "    return freq_dict\n",
    "\n",
    "def date_range_len(start_yr, start_mth, end_yr, end_mth):\n",
    "    months = (end_yr - start_yr)*12 + (end_mth - start_mth) + 1\n",
    "    return months\n",
    "\n",
    "def get_date_df(months, start_yr, start_mth):\n",
    "    yr_list = []\n",
    "    mth_list = []\n",
    "    date_list = []\n",
    "    curr_yr = start_yr\n",
    "    curr_mth = start_mth\n",
    "    for i in range(months):\n",
    "        yr_list.append(curr_yr)\n",
    "        mth_list.append(curr_mth)\n",
    "        date_list.append(dt.date(curr_yr, curr_mth, 1))\n",
    "        if curr_mth < 12:\n",
    "            curr_mth += 1\n",
    "        else:\n",
    "            curr_mth = 1\n",
    "            curr_yr += 1\n",
    "    date_df = pd.DataFrame(yr_list, columns=['year'])\n",
    "    date_df['month'] = mth_list\n",
    "    date_df['date'] = date_list\n",
    "    return date_df\n",
    "\n",
    "def sort_dict(my_dict, num=30, print_output=True):\n",
    "    sorted_dict_raw = sorted(my_dict, key=my_dict.get, reverse=True)\n",
    "    sorted_dict = sorted_dict_raw[0:num]\n",
    "    if print_output == True:\n",
    "        for i in sorted_dict:\n",
    "            print(i, my_dict[i])\n",
    "    return sorted_dict\n",
    "\n",
    "def get_tf(str1):\n",
    "    tf = {}    \n",
    "    no_punct = re.sub(r'[^\\w\\s]','', str1)\n",
    "    curr_str = no_punct.split()\n",
    "    lower_str = [j.lower() for j in curr_str]\n",
    "    final_str = [j for j in lower_str if j not in stopwords]\n",
    "    for i in final_str:\n",
    "        if i in tf:\n",
    "            tf[i] += 1\n",
    "        else:\n",
    "            tf[i] = 1\n",
    "    return tf\n",
    "\n",
    "def get_tfidf(tf):\n",
    "    tfidf = {}\n",
    "    for i, val in tf.items():\n",
    "        tfidf[i] = (1 + np.log(val)) * inv_freq[i]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_yr = 1985\n",
    "start_mth = 1\n",
    "end_yr = 1989\n",
    "end_mth = 12\n",
    "\n",
    "months = date_range_len(start_yr, start_mth, end_yr, end_mth)\n",
    "date_df = get_date_df(months, start_yr, start_mth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "headlines_list = []\n",
    "keywords_list = []\n",
    "lead_para_list = []\n",
    "for i, yr in enumerate(date_df['year']):\n",
    "    print(yr, date_df['month'][i])\n",
    "    freq_dict, headlines, keywords, lead_paragraphs = get_freq_dict(yr, date_df['month'][i], True, True)\n",
    "    \n",
    "    dict_list.append(freq_dict)\n",
    "    headlines_list.append(headlines)\n",
    "    keywords_list.append(keywords)\n",
    "    lead_para_list.append(lead_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "read_pickle = 1\n",
    "\n",
    "if read_pickle == 0:\n",
    "    pickle.dump(dict_list, open(\"freq.p\", \"wb\"))\n",
    "    pickle.dump(headlines_list, open(\"head.p\", \"wb\"))\n",
    "    pickle.dump(keywords_list, open(\"key.p\", \"wb\"))\n",
    "    pickle.dump(lead_para_list, open(\"lead.p\", \"wb\"))\n",
    "else:\n",
    "    dict_list = pickle.load(open(\"freq.p\", \"rb\"))\n",
    "    headlines_list = pickle.load(open(\"head.p\", \"rb\"))\n",
    "    keywords_list = pickle.load(open(\"key.p\", \"rb\"))\n",
    "    lead_para_list = pickle.load(open(\"lead.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {}\n",
    "for dict_i in dict_list:\n",
    "    for key, val in dict_i.items():\n",
    "        if key in master_dict:\n",
    "            master_dict[key] += val\n",
    "        else:\n",
    "            master_dict[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead 301221\n",
      "new 92792\n",
      "said 86183\n",
      "company 80421\n",
      "today 72491\n",
      "reports 55446\n",
      "years 54186\n",
      "yesterday 53884\n",
      "net 53265\n",
      "share 51093\n",
      "qtr 48429\n",
      "york 47955\n",
      "mr 45418\n",
      "earns 40939\n",
      "1987 37450\n",
      "year 34683\n",
      "1988 32986\n",
      "president 32984\n",
      "states 30622\n",
      "american 30326\n",
      "united 29690\n",
      "30 28488\n",
      "31 28272\n",
      "million 27233\n",
      "city 26372\n",
      "state 26144\n",
      "1986 26107\n",
      "revenue 25458\n",
      "week 25211\n",
      "time 24998\n"
     ]
    }
   ],
   "source": [
    "most_words = sort_dict(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_items = 0\n",
    "for i in lead_para_list:\n",
    "    tot_items += len(i)\n",
    "\n",
    "inv_freq ={}\n",
    "for i, val in master_dict.items():\n",
    "    inv_freq[i] = 1 + np.log(tot_items/val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bork 43.43982210448037\n",
      "borks 41.65446351037619\n",
      "plunge 41.59845271259585\n",
      "twins 39.74949159286405\n",
      "3first 39.35794079747119\n",
      "jaffna 39.05317186130321\n",
      "persian 38.67560047094727\n",
      "sept 38.218183869447486\n",
      "tamil 38.08239856748198\n",
      "tibet 37.95343320563901\n",
      "9mo 37.58469652869838\n",
      "cardinals 37.141105149119376\n",
      "amadoumahtar 36.823103620289764\n",
      "replacement 36.69387938070131\n",
      "nomination 36.299329050062795\n",
      "mbow 36.14124561278975\n",
      "minnesota 36.07417193206584\n",
      "gulf 35.49417995066303\n",
      "bancorp 35.3591213168108\n",
      "stock 35.203079777755825\n",
      "metrodome 35.16373205873701\n",
      "thirdquarter 35.11552557434725\n",
      "12mo 34.90684163194999\n",
      "sri 34.803667103128696\n",
      "nobel 34.335361027869304\n",
      "collapse 34.11924242658954\n",
      "whitey 34.111295634497154\n",
      "nyse 34.0970776891789\n",
      "zaccaro 34.07435282351327\n",
      "americanregistered 34.02306053468121\n"
     ]
    }
   ],
   "source": [
    "# Score the most important terms for a given month using TF-IDF\n",
    "mth_dict, mth_headlines, mth_keywords, mth_paragraphs = get_freq_dict(1987, 10, get_meta=True, get_lead=True)\n",
    "tf_mth = get_tf_mth(mth_paragraphs)\n",
    "tfidf_mth = get_tfidf(tf_mth)\n",
    "# Sort by TF-IDF\n",
    "top_score_words = sort_dict(tfidf_mth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapsed = [i for sublist in keywords_list for i in sublist]\n",
    "\n",
    "def get_key_str(key_list):\n",
    "    key_str = ''\n",
    "    for j in key_list:\n",
    "        for i in j:\n",
    "            if i['name'] == 'subject':\n",
    "                key_str = key_str + ' ' + i['value']\n",
    "    return key_str\n",
    "\n",
    "# Get the keyword for each article\n",
    "key_chosen = []\n",
    "for sublist in keywords_list:\n",
    "    mth_key_str = get_key_str(sublist)\n",
    "    mth_freq = get_tf(mth_key_str)\n",
    "    key_freq = {}\n",
    "    for index, val in mth_freq.items():\n",
    "        key_freq[index] = 1 + np.log(val/sum(mth_freq.values()))\n",
    "    temp_list = []\n",
    "    for j in sublist:\n",
    "        article_key_str = get_key_str([j])\n",
    "        article_freq = get_tf(article_key_str)\n",
    "        tfdf_key = {}\n",
    "        for index2, val2 in article_freq.items():\n",
    "            tfdf_key[index2] = (1 + np.log(val2)) * key_freq[index2]\n",
    "        if tfdf_key == {}:\n",
    "            temp_list.append([])\n",
    "        else:\n",
    "            temp_list.append(sort_dict(tfdf_key, print_output=False)[0])\n",
    "    key_chosen.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apparel'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_chosen[0][101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_trend(words, dict_list):\n",
    "    # stemmed_words = [ps.stem(j) for j in words]\n",
    "    word_counts = []\n",
    "    for i in dict_list:\n",
    "        temp_sum = 0\n",
    "        for w in words:\n",
    "            try:\n",
    "                temp_sum += i[w]\n",
    "            except:\n",
    "                temp_sum += 0\n",
    "        word_counts.append(temp_sum)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = ['earthquake']\n",
    "word2 = ['plunge']\n",
    "y1 = word_trend(word1, dict_list)\n",
    "y2 = word_trend(word2, dict_list)\n",
    "correl = np.corrcoef(np.array([y1, y2]), rowvar=True)[0, 1]\n",
    "correl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "\n",
    "ax.plot(date_df['date'], y1, label=word1)\n",
    "ax.plot(date_df['date'], y2, c='red', label=word2)\n",
    "\n",
    "ax.set_ylabel('Monthly Articles with Word')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_word_headlines_specific(yr, mth, words):\n",
    "    word_headlines = []\n",
    "    # stemmed_words = [ps.stem(j) for j in words]\n",
    "    out_dict, out_headlines, keywords, lead_paragraphs = get_freq_dict(yr, mth, get_lead=True)\n",
    "    for h in lead_paragraphs:\n",
    "        if h == None:\n",
    "            h = ''\n",
    "        curr_head = h.split()\n",
    "        lower_head = [j.lower() for j in curr_head]\n",
    "        # stemmed_head = [ps.stem(j) for j in lower_head]\n",
    "        found = True\n",
    "        for w in words:\n",
    "            if w not in lower_head:\n",
    "                found = False\n",
    "        if found:\n",
    "            word_headlines.append(h)\n",
    "    return word_headlines\n",
    "\n",
    "yr = 1987\n",
    "mth = 10\n",
    "words = ['bork']\n",
    "get_word_headlines_specific(yr, mth, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_headlines_all(words, headlines_list):\n",
    "    word_headlines = []\n",
    "    for headlines in headlines_list:\n",
    "        for h in headlines:\n",
    "            if h == None:\n",
    "                h = ''\n",
    "            curr_head = h.split()\n",
    "            lower_head = [j.lower() for j in curr_head]\n",
    "            # stemmed_head = [ps.stem(j) for j in lower_head]\n",
    "            found = True\n",
    "            for w in words:\n",
    "                if w not in lower_head:\n",
    "                    found = False\n",
    "            if found:\n",
    "                word_headlines.append(h)\n",
    "    return word_headlines\n",
    "\n",
    "words = ['plunge']\n",
    "word_headlines = get_word_headlines_all(words, lead_para_list)\n",
    "word_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
